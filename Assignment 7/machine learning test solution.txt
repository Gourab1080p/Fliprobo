1. The value of correlation coefficient will always be:

Ans: C) between -1 and 1

2. Which of the following cannot be used for dimensionality reduction?

Ans: D) Ridge Regularisation

3. Which of the following is not a kernel in Support Vector Machines?

Ans: C) hyperplane

4. Amongst the following, which one is least suitable for a dataset having non-linear decision boundaries?

Ans: D) Support Vector Classifier

5. In a Linear Regression problem, ‘X’ is independent variable and ‘Y’ is dependent variable, where ‘X’ represents weight in pounds. If you convert the unit of ‘X’ to kilograms, then new coefficient of ‘X’ will be?

Ans: A) 2.205 × old coefficient of ‘X’

6. As we increase the number of estimators in ADABOOST Classifier, what happens to the accuracy of the model?

Ans: B) increases

7. Which of the following is not an advantage of using random forest instead of decision trees?

Ans: C) Random Forests are easy to interpret

8. Which of the following are correct about Principal Components?

Ans. B) Principal Components are calculated using unsupervised learning techniques
     C) Principal Components are linear combinations of Linear Variables. 


9. Which of the following are applications of clustering?

Ans B) Identifying loan defaulters in a bank on the basis of previous years’ data of loan accounts.
    C) Identifying spam or ham emails

10. Which of the following is(are) hyper parameters of a decision tree?

Ans: A) max_depth
     B) max_features
     D) min_samples_leaf

11. What are outliers? Explain the Inter Quartile Range(IQR) method for outlier detection

Ans: An outlier is a data point that differs significantly from other observations.

A. Calculate the interquartile range for the data (IQR = Q3 - Q1).
B. Multiply the interquartile range (IQR) by 1.5 (IQR*1.5).
C. Subtract 1.5 x (IQR) from the first quartile (Lower Bound: (Q1 - 1.5 * IQR)). Any number less than this is treated as outlier.
D. Add 1.5 x (IQR) to the third quartile (Upper Bound: (Q3 + 1.5 * IQR)). Any number greater than this is treated as outlier.
 
12. What is the primary difference between bagging and boosting algorithms?

Ans: Bagging:-
a) It is the simplest way of combining predictions that belong to the similar type.
b) Each model receives equal weight.
c) It tries to solve over-fitting problem.

Boosting:- 
a) It is the way of combining predictions that belongs to the different types.
b) Models are weighted according to their performance.
c) It tries to reduce bias.

13. What is adjusted R2 in logistic regression. How is it calculated?

Ans: Adjusted R2 denotes the corresponding value but for the null model - the model with only an intercept and no covariates.
R2 = 1 – [ln LL(Mˆfull)]/[ln LL(Mˆintercept)]

14. What is the difference between standardisation and normalisation?

Ans: Normalization usually means to scale a variable to have a values between 0 and 1, while standardization transforms data to have a mean of zero and a standard deviation of 1. 

15. What is cross-validation? Describe one advantage and one disadvantage of using cross-validation

Ans:Cross-validation is a technique in which we train our model using the subset of the data-set and then evaluate using the complementary subset of the data-set.
Advantage: It prevents our model from overfitting the training dataset.
Disadvantage: Cross Validation drastically increases the training time.